# ML Inference Latency Optimizer

A production-style ML inference system that monitors real-time latency and evaluates SLA compliance.

## Features
- Dual ML models with accuracyâ€“latency tradeoffs
- FastAPI inference service
- Rolling latency metrics (avg, p95)
- SLA violation detection

## Progress
- Day 1: Train large and small models with latency measurement
- Day 2: FastAPI inference service
- Day 3: Rolling latency monitor and SLA evaluation
